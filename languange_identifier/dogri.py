#here we give input as string of paragraph of containing some text about dogri language 
#and this code retrun some information like email,mobile number, sentences ,words with the help of re and nltk module 

import re
from nltk.tokenize import word_tokenize, sent_tokenize

# Dogri text
dogri_text = '''
ğ‘ ©ğ‘ ¬ğ‘ ¤ğ‘ ³ ğ‘ ¢ğ‘ ğ‘ ¯ğ‘ Šğ‘ ¹ğ‘ ‹ ğ‘ ¢ğ‘ ´ğ‘ ªğ‘ ¹ğ‘ ¢ğ‘ ¬ ğ‘ ™ğ‘ ³ ğ‘ €ğ‘ œğ‘ ­ğ‘ Šğ‘ ¬ğ‘ ¤ğ‘ ³ğ‘ · ğ‘ ›ğ‘ ³ ğ‘  ğ‘ ­ğ‘ §ğ‘ ³ ğ‘  ğ‘ ‘ğ‘ ğ‘ ¢ğ‘ ´ ğ‘ šğ‘ ¢ğ‘ ¬ğ‘ · ğ‘ ©ğ‘ ¯ğ‘ ™ğ‘ ´ğ‘ ·ğ‘ ™ğ‘ ¤ ğ‘ ™ğ‘ ³ ğ‘  ğ‘ ¤ğ‘ µğ‘  ğ‘ ¤ ğ‘ à¥¤ ğ‘ „'ğ‘ ğ‘ ³ğ‘ ·ğ‘ Œğ‘ ® ğ‘  ğ‘ ¯ğ‘ ›ğ‘ ¹ğ‘ œğ‘ ® ğ‘ ™ğ‘ ³ ğ‘ ‘ğ‘ ¢ğ‘ ®ğ‘ ¤ğ‘ ´ ğ‘ ›ğ‘ ® ğ‘ ›ğ‘ ³ğ‘  ğ‘ šğ‘ ¹ğ‘ ªğ‘ µğ‘ ƒ ğ‘ ‡ ğ‘ ™ğ‘ ³ ğ‘ „'ğ‘ ğ‘ ³ğ‘ ·ğ‘ Œğ‘ ® ğ‘ ğ‘ ğ‘ °ğ‘ ·-ğ‘  ğ‘ ­ğ‘ ğ‘ ¹ğ‘ ğ‘ ³ğ‘ · ğ‘ ¡ğ‘ ¬ğ‘ ƒğ‘ ğ‘ ¬ğ‘ ¤ğ‘ ³ ğ‘ ›ğ‘ ³ ğ‘ ¡ğ‘ ¬ğ‘ ¦ğ‘ ´ ğ‘ Šğ‘ ğ‘ ¹ğ‘ ğ‘ ´ ğ‘  ğ‘ ¹ğ‘ £ğ‘ ªğ‘ ¬ğ‘ ¤ ğ‘ Šğ‘ ¤ğ‘ ğ‘ ¬ ğ‘ ¥ğ‘ µğ‘ «ğ‘ ›ğ‘ ¬ ğ‘ ‡à¥¤
ğ‘ ©ğ‘ ¬ğ‘ ¤ğ‘ ³ ğ‘ ¢ğ‘ ğ‘ ¯ğ‘ Šğ‘ ¹ğ‘ ‹ ğ‘ ¢ğ‘ ´ğ‘ ªğ‘ ¹ğ‘ ¢ğ‘ ¬ ğ‘ ™ğ‘ ³ ğ‘ €ğ‘ œğ‘ ­ğ‘ Šğ‘ ¬ğ‘ ¤ğ‘ ³ğ‘ · ğ‘ ›ğ‘ ³ ğ‘  ğ‘ ­ğ‘ §ğ‘ ³ ğ‘  ğ‘ ‘ğ‘ ğ‘ ¢ğ‘ ´ ğ‘ šğ‘ ¢ğ‘ ¬ğ‘ · ğ‘ ©ğ‘ ¯ğ‘ ™ğ‘ ´ğ‘ ·ğ‘ ™ğ‘ ¤ ğ‘ ™ğ‘ ³ ğ‘  ğ‘ ¤ğ‘ µğ‘  ğ‘ ¤ ğ‘ à¥¤ 

ğ‘ „ğ‘ ğ‘ ©ğ‘ ¬ğ‘ ğ‘ ®ğ‘ Œğ‘ ¥ğ‘ ¢ğ‘ ³ğ‘ ¢ğ‘ ¤ ğ‘  ğ‘ ¯ğ‘ ›ğ‘ ¹ğ‘ œğ‘ ® ğ‘ ‘ğ‘ ¢ğ‘ ®ğ‘ ¤ğ‘ ´ dogri.example@à¤¡à¥‹à¤—à¥à¤°à¥€mail.com ğ‘ ›ğ‘ ® ğ‘ ›ğ‘ ³ğ‘  ğ‘ šğ‘ ¹ğ‘ ªğ‘ µğ‘ ƒà¥¤ 

ğ‘ „ğ‘ ¥ğ‘ ³ğ‘ ğ‘ °ğ‘ ¬ ğ‘ ğ‘ ğ‘ ¤ğ‘ œğ‘ ¬ ğ‘ šğ‘ ¤ğ‘ ³ +91 12345 67890 ğ‘ ğ‘ ­ğ‘ šğ‘ ¤ğ‘ ³ğ‘ à¥¤ 
dogri_text@example.com is also a valid email for testing purposes.

'''

# Unicode range for Dogri language
dogri_unicode_block = r'[\u11680-\u116CF]'
dogri_digit_block = r'[\u0966-\u096F]'

# 1. Word Tokenization
#when we use re moudule this is not correclty capture the all dogri words 
# dogri_word_pattern = rf'{dogri_unicode_block}+'
# dogri_words = re.findall(dogri_word_pattern, dogri_text)
# print("Dogri Words:", dogri_words)

dogri_words=wordtokenzie(dogri_text)
print("Dogri Words:", dogri_words)

# 2. Sentence Tokenization (Sentences ending with à¥¤ or ! or ?)
dogri_sentence_pattern = rf'{dogri_unicode_block}[\s\u11680-\u116CF]*[à¥¤!?]'
dogri_sentences = re.findall(dogri_sentence_pattern, dogri_text)
print("\nDogri Sentences:", dogri_sentences)

# 2.1 NLTK-based Sentence Tokenization (fallback if specific sentence pattern fails)
dogri_sentences_nltk = sent_tokenize(dogri_text)  # Adjust NLTK tokenizers if necessary
print("\nDogri Sentences (NLTK):", dogri_sentences_nltk)

# 3. Paragraph Tokenization
dogri_paragraphs = dogri_text.split("\n\n")
print("\nDogri Paragraphs:")
for para in dogri_paragraphs:
    print(para)

# 4. Email Extraction (Dogri + English Emails)
email_pattern_dogri = rf'[{dogri_unicode_block}a-zA-Z0-9._%+-]+@[{dogri_unicode_block}a-zA-Z0-9.-]+\.[{dogri_unicode_block}a-zA-Z]{{2,}}'
dogri_emails = re.findall(email_pattern_dogri, dogri_text)
print("\nDogri Emails:", dogri_emails)

# 5. Mobile Number Extraction (Dogri and English Digits)
dogri_mobile_pattern = rf'(?:\+91\s?)?(?:[{dogri_digit_block}0-9]{{2}}\s?)?[{dogri_digit_block}0-9]{{5}}\s?[{dogri_digit_block}0-9]{{5}}'
dogri_mobile_numbers = re.findall(dogri_mobile_pattern, dogri_text)
print("\nDogri Mobile Numbers:", dogri_mobile_numbers)

