PS C:\Users\yashi\OneDrive\Desktop\deep learning> python -u "c:\Users\yashi\OneDrive\Desktop\deep learning\basics\new.py"
2025-03-21 00:09:07.976862: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-03-21 00:09:08.764061: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
WARNING:tensorflow:From C:\Users\yashi\AppData\Roaming\Python\Python310\site-packages\tf_keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.

Map: 100%|██████████████████████████████████████████████████████████████████████████████████████| 176003/176003 [00:38<00:00, 4533.55 examples/s] 
Map: 100%|████████████████████████████████████████████████████████████████████████████████████████| 22000/22000 [00:04<00:00, 4470.41 examples/s] 
Map: 100%|████████████████████████████████████████████████████████████████████████████████████████| 22001/22001 [00:05<00:00, 4384.44 examples/s] 
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/muril-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
c:\Users\yashi\OneDrive\Desktop\deep learning\basics\new.py:99: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
{'loss': 2.7154, 'grad_norm': 1.2281954288482666, 'learning_rate': 1.963636363636364e-05, 'epoch': 0.09}                                          
{'loss': 1.5875, 'grad_norm': 1.6042407751083374, 'learning_rate': 1.9273454545454546e-05, 'epoch': 0.18}
{'loss': 0.7198, 'grad_norm': 1.8365135192871094, 'learning_rate': 1.8909818181818183e-05, 'epoch': 0.27}
{'loss': 0.3855, 'grad_norm': 0.5678682923316956, 'learning_rate': 1.8546909090909093e-05, 'epoch': 0.36}                                         
{'loss': 0.2535, 'grad_norm': 0.7813496589660645, 'learning_rate': 1.818327272727273e-05, 'epoch': 0.45}                                          
{'loss': 0.2084, 'grad_norm': 5.855153560638428, 'learning_rate': 1.7820363636363637e-05, 'epoch': 0.55}                                          
{'loss': 0.1817, 'grad_norm': 0.25859320163726807, 'learning_rate': 1.7456727272727274e-05, 'epoch': 0.64}                                        
{'loss': 0.1697, 'grad_norm': 0.24759000539779663, 'learning_rate': 1.709309090909091e-05, 'epoch': 0.73}                                         
{'loss': 0.1596, 'grad_norm': 0.7864310145378113, 'learning_rate': 1.6729454545454548e-05, 'epoch': 0.82}                                         
{'loss': 0.1584, 'grad_norm': 1.4442858695983887, 'learning_rate': 1.6366545454545455e-05, 'epoch': 0.91}                                         
{'loss': 0.1499, 'grad_norm': 3.992811918258667, 'learning_rate': 1.6003636363636366e-05, 'epoch': 1.0}                                           
 20%|███████████████████▊                                                                               | 5501/27500 [1:41:38<5:40:16,  1.08it/s]Trainer is attempting to log a value of "{'asm_Beng': {'precision': 0.9880358923230309, 'recall': 0.991, 'f1-score': 0.9895157264103844, 'support': 1000.0}, 'ben_Beng': {'precision': 1.0, 'recall': 0.997, 'f1-score': 0.9984977466199298, 'support': 1000.0}, 'brx_deva': {'precision': 0.9018518518518519, 'recall': 0.974, 'f1-score': 0.9365384615384615, 'support': 1000.0}, 'doi_Deva': {'precision': 0.9776536312849162, 'recall': 0.875, 'f1-score': 0.9234828496042217, 'support': 1000.0}, 'eng_Latn': {'precision': 0.9940357852882704, 'recall': 1.0, 'f1-score': 0.9970089730807578, 'support': 1000.0}, 'gom_deva': {'precision': 0.9581673306772909, 'recall': 0.962, 'f1-score': 0.9600798403193613, 'support': 1000.0}, 'guj_Gujr': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'hin_Deva': {'precision': 0.9939148073022313, 'recall': 0.98, 'f1-score': 0.9869083585095669, 'support': 1000.0}, 'kan_Knda': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'kas_Arab': {'precision': 0.9812623274161736, 'recall': 0.995, 'f1-score': 0.9880834160873883, 'support': 1000.0}, 'mai_Deva': {'precision': 0.8058419243986255, 'recall': 0.938, 'f1-score': 0.866913123844732, 'support': 1000.0}, 'mal_Mlym': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'mar_Deva': {'precision': 0.9828973843058351, 'recall': 0.977, 'f1-score': 0.9799398194583752, 'support': 1000.0}, 'mni_Mtei': {'precision': 0.875, 'recall': 0.147, 'f1-score': 0.2517123287671233, 'support': 1000.0}, 'npi_Deva': {'precision': 0.9751351351351352, 'recall': 0.902, 'f1-score': 0.9371428571428572, 'support': 1000.0}, 'ory_Orya': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'pan_Guru': {'precision': 0.9970059880239521, 'recall': 0.999, 'f1-score': 0.998001998001998, 'support': 1000.0}, 'sat_olck': {'precision': 0.5364130434782609, 'recall': 0.987, 'f1-score': 0.6950704225352112, 'support': 1000.0}, 'snd_Deva': {'precision': 0.959445037353255, 'recall': 0.899, 'f1-score': 0.9282395456892101, 'support': 1000.0}, 'tam_Taml': {'precision': 0.998001998001998, 'recall': 0.999, 'f1-score': 0.9985007496251874, 'support': 1000.0}, 'tel_Telu': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'urd_Arab': {'precision': 0.9959349593495935, 'recall': 0.98, 'f1-score': 0.9879032258064516, 'support': 1000.0}, 'accuracy': 0.9364545454545454, 'macro avg': {'precision': 0.9509362316450194, 'recall': 0.9364545454545454, 'f1-score': 0.9283427019564189, 'support': 22000.0}, 'weighted avg': {'precision': 0.9509362316450191, 'recall': 0.9364545454545454, 'f1-score': 0.9283427019564189, 'support': 22000.0}}" of type <class 'dict'> for key "eval/classification_report" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
{'eval_loss': 0.14335893094539642, 'eval_accuracy': 0.9364545454545454, 'eval_classification_report': {'asm_Beng': {'precision': 0.9880358923230309, 'recall': 0.991, 'f1-score': 0.9895157264103844, 'support': 1000.0}, 'ben_Beng': {'precision': 1.0, 'recall': 0.997, 'f1-score': 0.9984977466199298, 'support': 1000.0}, 'brx_deva': {'precision': 0.9018518518518519, 'recall': 0.974, 'f1-score': 0.9365384615384615, 'support': 1000.0}, 'doi_Deva': {'precision': 0.9776536312849162, 'recall': 0.875, 'f1-score': 0.9234828496042217, 'support': 1000.0}, 'eng_Latn': {'precision': 0.9940357852882704, 'recall': 1.0, 'f1-score': 0.9970089730807578, 'support': 1000.0}, 'gom_deva': {'precision': 0.9581673306772909, 'recall': 0.962, 'f1-score': 0.9600798403193613, 'support': 1000.0}, 'guj_Gujr': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'hin_Deva': {'precision': 0.9939148073022313, 'recall': 0.98, 'f1-score': 0.9869083585095669, 'support': 1000.0}, 'kan_Knda': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'kas_Arab': {'precision': 0.9812623274161736, 'recall': 0.995, 'f1-score': 0.9880834160873883, 'support': 1000.0}, 'mai_Deva': {'precision': 0.8058419243986255, 'recall': 0.938, 'f1-score': 0.866913123844732, 'support': 1000.0}, 'mal_Mlym': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'mar_Deva': {'precision': 0.9828973843058351, 'recall': 0.977, 'f1-score': 0.9799398194583752, 'support': 1000.0}, 'mni_Mtei': {'precision': 0.875, 'recall': 0.147, 'f1-score': 0.2517123287671233, 'support': 1000.0}, 'npi_Deva': {'precision': 0.9751351351351352, 'recall': 0.902, 'f1-score': 0.9371428571428572, 'support': 1000.0}, 'ory_Orya': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'pan_Guru': {'precision': 0.9970059880239521, 'recall': 0.999, 'f1-score': 0.998001998001998, 'support': 1000.0}, 'sat_olck': {'precision': 0.5364130434782609, 'recall': 0.987, 'f1-score': 0.6950704225352112, 'support': 1000.0}, 'snd_Deva': {'precision': 0.959445037353255, 'recall': 0.899, 'f1-score': 0.9282395456892101, 'support': 1000.0}, 'tam_Taml': {'precision': 0.998001998001998, 'recall': 0.999, 'f1-score': 0.9985007496251874, 'support': 1000.0}, 'tel_Telu': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'urd_Arab': {'precision': 0.9959349593495935, 'recall': 0.98, 'f1-score': 0.9879032258064516, 'support': 1000.0}, 'accuracy': 0.9364545454545454, 'macro avg': {'precision': 0.9509362316450194, 'recall': 0.9364545454545454, 'f1-score': 0.9283427019564189, 'support': 22000.0}, 'weighted avg': {'precision': 0.9509362316450191, 'recall': 0.9364545454545454, 'f1-score': 0.9283427019564189, 'support': 22000.0}}, 'eval_runtime': 105.7, 'eval_samples_per_second': 208.136, 'eval_steps_per_second': 13.009, 'epoch': 1.0}
{'loss': 0.1294, 'grad_norm': 0.858928382396698, 'learning_rate': 1.5640000000000003e-05, 'epoch': 1.09}                                          
{'loss': 0.1252, 'grad_norm': 0.6114569306373596, 'learning_rate': 1.527636363636364e-05, 'epoch': 1.18}
{'loss': 0.1172, 'grad_norm': 0.6790560483932495, 'learning_rate': 1.4912727272727275e-05, 'epoch': 1.27}                                         
{'loss': 0.1234, 'grad_norm': 0.6864199638366699, 'learning_rate': 1.4549818181818182e-05, 'epoch': 1.36}                                         
{'loss': 0.1156, 'grad_norm': 0.2997000217437744, 'learning_rate': 1.4186181818181819e-05, 'epoch': 1.45}                                         
{'loss': 0.1217, 'grad_norm': 3.54879093170166, 'learning_rate': 1.3822545454545455e-05, 'epoch': 1.55}                                           
{'loss': 0.116, 'grad_norm': 1.3534327745437622, 'learning_rate': 1.345890909090909e-05, 'epoch': 1.64}                                           
{'loss': 0.1129, 'grad_norm': 0.2771150767803192, 'learning_rate': 1.3095272727272727e-05, 'epoch': 1.73}                                         
{'loss': 0.107, 'grad_norm': 2.578488826751709, 'learning_rate': 1.2731636363636364e-05, 'epoch': 1.82}                                           
{'loss': 0.1147, 'grad_norm': 6.455466270446777, 'learning_rate': 1.2368e-05, 'epoch': 1.91}                                                      
{'loss': 0.1102, 'grad_norm': 30.39008903503418, 'learning_rate': 1.200509090909091e-05, 'epoch': 2.0}                                            
 40%|███████████████████████████████████████▏                                                          | 11002/27500 [3:20:10<4:16:54,  1.07it/s]Trainer is attempting to log a value of "{'asm_Beng': {'precision': 0.9910358565737052, 'recall': 0.995, 'f1-score': 0.9930139720558883, 'support': 1000.0}, 'ben_Beng': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'brx_deva': {'precision': 0.9804928131416838, 'recall': 0.955, 'f1-score': 0.9675785207700102, 'support': 1000.0}, 'doi_Deva': {'precision': 0.9630411826821542, 'recall': 0.912, 'f1-score': 0.9368258859784283, 'support': 1000.0}, 'eng_Latn': {'precision': 0.999, 'recall': 0.999, 'f1-score': 0.999, 'support': 1000.0}, 'gom_deva': {'precision': 0.9655172413793104, 'recall': 0.98, 'f1-score': 0.9727047146401985, 'support': 1000.0}, 'guj_Gujr': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'hin_Deva': {'precision': 0.9909729187562688, 'recall': 0.988, 'f1-score': 0.9894842263395093, 'support': 1000.0}, 'kan_Knda': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'kas_Arab': {'precision': 0.993993993993994, 'recall': 0.993, 'f1-score': 0.9934967483741871, 'support': 1000.0}, 'mai_Deva': {'precision': 0.8210526315789474, 'recall': 0.936, 'f1-score': 0.874766355140187, 'support': 1000.0}, 'mal_Mlym': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'mar_Deva': {'precision': 0.9948875255623721, 'recall': 0.973, 'f1-score': 0.9838220424671386, 'support': 1000.0}, 'mni_Mtei': {'precision': 0.6074406670942912, 'recall': 0.947, 'f1-score': 0.7401328644001564, 'support': 1000.0}, 'npi_Deva': {'precision': 0.9362348178137652, 'recall': 0.925, 'f1-score': 0.9305835010060363, 'support': 1000.0}, 'ory_Orya': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'pan_Guru': {'precision': 0.999, 'recall': 0.999, 'f1-score': 0.999, 'support': 1000.0}, 'sat_olck': {'precision': 0.8820861678004536, 'recall': 0.389, 'f1-score': 0.5399028452463567, 'support': 1000.0}, 'snd_Deva': {'precision': 0.962303664921466, 'recall': 0.919, 'f1-score': 0.9401534526854219, 'support': 1000.0}, 'tam_Taml': {'precision': 0.9970089730807578, 'recall': 1.0, 'f1-score': 0.9985022466300549, 'support': 1000.0}, 'tel_Telu': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'urd_Arab': {'precision': 0.993, 'recall': 0.993, 'f1-score': 0.993, 'support': 1000.0}, 'accuracy': 0.9501363636363637, 'macro avg': {'precision': 0.9580485661081439, 'recall': 0.9501363636363636, 'f1-score': 0.9478166988969804, 'support': 22000.0}, 'weighted avg': {'precision': 0.9580485661081442, 'recall': 0.9501363636363637, 'f1-score': 0.9478166988969806, 'support': 22000.0}}" of type <class 'dict'> for key "eval/classification_report" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
{'eval_loss': 0.11261589825153351, 'eval_accuracy': 0.9501363636363637, 'eval_classification_report': {'asm_Beng': {'precision': 0.9910358565737052, 'recall': 0.995, 'f1-score': 0.9930139720558883, 'support': 1000.0}, 'ben_Beng': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'brx_deva': {'precision': 0.9804928131416838, 'recall': 0.955, 'f1-score': 0.9675785207700102, 'support': 1000.0}, 'doi_Deva': {'precision': 0.9630411826821542, 'recall': 0.912, 'f1-score': 0.9368258859784283, 'support': 1000.0}, 'eng_Latn': {'precision': 0.999, 'recall': 0.999, 'f1-score': 0.999, 'support': 1000.0}, 'gom_deva': {'precision': 0.9655172413793104, 'recall': 0.98, 'f1-score': 0.9727047146401985, 'support': 1000.0}, 'guj_Gujr': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'hin_Deva': {'precision': 0.9909729187562688, 'recall': 0.988, 'f1-score': 0.9894842263395093, 'support': 1000.0}, 'kan_Knda': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'kas_Arab': {'precision': 0.993993993993994, 'recall': 0.993, 'f1-score': 0.9934967483741871, 'support': 1000.0}, 'mai_Deva': {'precision': 0.8210526315789474, 'recall': 0.936, 'f1-score': 0.874766355140187, 'support': 1000.0}, 'mal_Mlym': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'mar_Deva': {'precision': 0.9948875255623721, 'recall': 0.973, 'f1-score': 0.9838220424671386, 'support': 1000.0}, 'mni_Mtei': {'precision': 0.6074406670942912, 'recall': 0.947, 'f1-score': 0.7401328644001564, 'support': 1000.0}, 'npi_Deva': {'precision': 0.9362348178137652, 'recall': 0.925, 'f1-score': 0.9305835010060363, 'support': 1000.0}, 'ory_Orya': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'pan_Guru': {'precision': 0.999, 'recall': 0.999, 'f1-score': 0.999, 'support': 1000.0}, 'sat_olck': {'precision': 0.8820861678004536, 'recall': 0.389, 'f1-score': 0.5399028452463567, 'support': 1000.0}, 'snd_Deva': {'precision': 0.962303664921466, 'recall': 0.919, 'f1-score': 0.9401534526854219, 'support': 1000.0}, 'tam_Taml': {'precision': 0.9970089730807578, 'recall': 1.0, 'f1-score': 0.9985022466300549, 'support': 1000.0}, 'tel_Telu': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'urd_Arab': {'precision': 0.993, 'recall': 0.993, 'f1-score': 0.993, 'support': 1000.0}, 'accuracy': 0.9501363636363637, 'macro avg': {'precision': 0.9580485661081439, 'recall': 0.9501363636363636, 'f1-score': 0.9478166988969804, 'support': 22000.0}, 'weighted avg': {'precision': 0.9580485661081442, 'recall': 0.9501363636363637, 'f1-score': 0.9478166988969806, 'support': 22000.0}}, 'eval_runtime': 104.1701, 'eval_samples_per_second': 211.193, 'eval_steps_per_second': 13.2, 'epoch': 2.0}
{'loss': 0.0966, 'grad_norm': 1.0313032865524292, 'learning_rate': 1.1641454545454547e-05, 'epoch': 2.09}                                         
{'loss': 0.0996, 'grad_norm': 0.8427649736404419, 'learning_rate': 1.1277818181818183e-05, 'epoch': 2.18}
{'loss': 0.0963, 'grad_norm': 0.7254553437232971, 'learning_rate': 1.0914181818181819e-05, 'epoch': 2.27}                                         
{'loss': 0.0925, 'grad_norm': 6.861023902893066, 'learning_rate': 1.0550545454545455e-05, 'epoch': 2.36}                                          
{'loss': 0.1032, 'grad_norm': 0.3300583064556122, 'learning_rate': 1.0186909090909092e-05, 'epoch': 2.45}                                         
{'loss': 0.1009, 'grad_norm': 0.2784751057624817, 'learning_rate': 9.823272727272727e-06, 'epoch': 2.55}                                          
{'loss': 0.1011, 'grad_norm': 0.8293943405151367, 'learning_rate': 9.459636363636364e-06, 'epoch': 2.64}                                          
{'loss': 0.0946, 'grad_norm': 2.0444791316986084, 'learning_rate': 9.096e-06, 'epoch': 2.73}                                                      
{'loss': 0.0983, 'grad_norm': 0.9416452050209045, 'learning_rate': 8.732363636363637e-06, 'epoch': 2.82}                                          
{'loss': 0.0921, 'grad_norm': 0.423442542552948, 'learning_rate': 8.369454545454547e-06, 'epoch': 2.91}                                           
{'loss': 0.0929, 'grad_norm': 1.0649882555007935, 'learning_rate': 8.005818181818182e-06, 'epoch': 3.0}                                           
 60%|██████████████████████████████████████████████████████████▊                                       | 16503/27500 [4:58:29<2:50:30,  1.07it/s]Trainer is attempting to log a value of "{'asm_Beng': {'precision': 0.998989898989899, 'recall': 0.989, 'f1-score': 0.9939698492462311, 'support': 1000.0}, 'ben_Beng': {'precision': 1.0, 'recall': 0.999, 'f1-score': 0.9994997498749375, 'support': 1000.0}, 'brx_deva': {'precision': 0.8943533697632058, 'recall': 0.982, 'f1-score': 0.9361296472831268, 'support': 1000.0}, 'doi_Deva': {'precision': 0.9412371134020618, 'recall': 0.913, 'f1-score': 0.9269035532994924, 'support': 1000.0}, 'eng_Latn': {'precision': 0.999, 'recall': 0.999, 'f1-score': 0.999, 'support': 1000.0}, 'gom_deva': {'precision': 0.962671905697446, 'recall': 0.98, 'f1-score': 0.9712586719524281, 'support': 1000.0}, 'guj_Gujr': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'hin_Deva': {'precision': 0.9919759277833501, 'recall': 0.989, 'f1-score': 0.9904857285928893, 'support': 1000.0}, 'kan_Knda': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'kas_Arab': {'precision': 0.994994994994995, 'recall': 0.994, 'f1-score': 0.9944972486243121, 'support': 1000.0}, 'mai_Deva': {'precision': 0.8789625360230547, 'recall': 0.915, 'f1-score': 0.8966193042626164, 'support': 1000.0}, 'mal_Mlym': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'mar_Deva': {'precision': 0.9938900203665988, 'recall': 0.976, 'f1-score': 0.9848637739656912, 'support': 1000.0}, 'mni_Mtei': {'precision': 0.6165364583333334, 'recall': 0.947, 'f1-score': 0.7468454258675079, 'support': 1000.0}, 'npi_Deva': {'precision': 0.9723991507430998, 'recall': 0.916, 'f1-score': 0.9433573635427395, 'support': 1000.0}, 'ory_Orya': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'pan_Guru': {'precision': 1.0, 'recall': 0.999, 'f1-score': 0.9994997498749375, 'support': 1000.0}, 'sat_olck': {'precision': 0.886021505376344, 'recall': 0.412, 'f1-score': 0.562457337883959, 'support': 1000.0}, 'snd_Deva': {'precision': 0.9573804573804574, 'recall': 0.921, 'f1-score': 0.9388379204892966, 'support': 1000.0}, 'tam_Taml': {'precision': 1.0, 'recall': 0.999, 'f1-score': 0.9994997498749375, 'support': 1000.0}, 'tel_Telu': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'urd_Arab': {'precision': 0.9930209371884346, 'recall': 0.996, 'f1-score': 0.9945082376435347, 'support': 1000.0}, 'accuracy': 0.9511818181818181, 'macro avg': {'precision': 0.9582470125473764, 'recall': 0.9511818181818179, 'f1-score': 0.9490106051035745, 'support': 22000.0}, 'weighted avg': {'precision': 0.9582470125473764, 'recall': 0.9511818181818181, 'f1-score': 0.9490106051035744, 'support': 22000.0}}" of type <class 'dict'> for key "eval/classification_report" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
{'eval_loss': 0.10680445283651352, 'eval_accuracy': 0.9511818181818181, 'eval_classification_report': {'asm_Beng': {'precision': 0.998989898989899, 'recall': 0.989, 'f1-score': 0.9939698492462311, 'support': 1000.0}, 'ben_Beng': {'precision': 1.0, 'recall': 0.999, 'f1-score': 0.9994997498749375, 'support': 1000.0}, 'brx_deva': {'precision': 0.8943533697632058, 'recall': 0.982, 'f1-score': 0.9361296472831268, 'support': 1000.0}, 'doi_Deva': {'precision': 0.9412371134020618, 'recall': 0.913, 'f1-score': 0.9269035532994924, 'support': 1000.0}, 'eng_Latn': {'precision': 0.999, 'recall': 0.999, 'f1-score': 0.999, 'support': 1000.0}, 'gom_deva': {'precision': 0.962671905697446, 'recall': 0.98, 'f1-score': 0.9712586719524281, 'support': 1000.0}, 'guj_Gujr': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'hin_Deva': {'precision': 0.9919759277833501, 'recall': 0.989, 'f1-score': 0.9904857285928893, 'support': 1000.0}, 'kan_Knda': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'kas_Arab': {'precision': 0.994994994994995, 'recall': 0.994, 'f1-score': 0.9944972486243121, 'support': 1000.0}, 'mai_Deva': {'precision': 0.8789625360230547, 'recall': 0.915, 'f1-score': 0.8966193042626164, 'support': 1000.0}, 'mal_Mlym': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'mar_Deva': {'precision': 0.9938900203665988, 'recall': 0.976, 'f1-score': 0.9848637739656912, 'support': 1000.0}, 'mni_Mtei': {'precision': 0.6165364583333334, 'recall': 0.947, 'f1-score': 0.7468454258675079, 'support': 1000.0}, 'npi_Deva': {'precision': 0.9723991507430998, 'recall': 0.916, 'f1-score': 0.9433573635427395, 'support': 1000.0}, 'ory_Orya': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'pan_Guru': {'precision': 1.0, 'recall': 0.999, 'f1-score': 0.9994997498749375, 'support': 1000.0}, 'sat_olck': {'precision': 0.886021505376344, 'recall': 0.412, 'f1-score': 0.562457337883959, 'support': 1000.0}, 'snd_Deva': {'precision': 0.9573804573804574, 'recall': 0.921, 'f1-score': 0.9388379204892966, 'support': 1000.0}, 'tam_Taml': {'precision': 1.0, 'recall': 0.999, 'f1-score': 0.9994997498749375, 'support': 1000.0}, 'tel_Telu': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'urd_Arab': {'precision': 0.9930209371884346, 'recall': 0.996, 'f1-score': 0.9945082376435347, 'support': 1000.0}, 'accuracy': 0.9511818181818181, 'macro avg': {'precision': 0.9582470125473764, 'recall': 0.9511818181818179, 'f1-score': 0.9490106051035745, 'support': 22000.0}, 'weighted avg': {'precision': 0.9582470125473764, 'recall': 0.9511818181818181, 'f1-score': 0.9490106051035744, 'support': 22000.0}}, 'eval_runtime': 104.5932, 'eval_samples_per_second': 210.339, 'eval_steps_per_second': 13.146, 'epoch': 3.0}
{'loss': 0.0897, 'grad_norm': 0.9690197706222534, 'learning_rate': 7.642181818181818e-06, 'epoch': 3.09}                                          
{'loss': 0.0907, 'grad_norm': 1.386542797088623, 'learning_rate': 7.278545454545455e-06, 'epoch': 3.18}
{'loss': 0.0888, 'grad_norm': 0.07848196476697922, 'learning_rate': 6.914909090909091e-06, 'epoch': 3.27}                                         
{'loss': 0.0925, 'grad_norm': 4.757051944732666, 'learning_rate': 6.552000000000001e-06, 'epoch': 3.36}                                           
{'loss': 0.0803, 'grad_norm': 3.651621103286743, 'learning_rate': 6.188363636363637e-06, 'epoch': 3.45}                                           
{'loss': 0.0901, 'grad_norm': 2.135953664779663, 'learning_rate': 5.824727272727273e-06, 'epoch': 3.54}                                           
{'loss': 0.0861, 'grad_norm': 0.02653356082737446, 'learning_rate': 5.4610909090909096e-06, 'epoch': 3.64}                                        
{'loss': 0.0854, 'grad_norm': 1.043792724609375, 'learning_rate': 5.0974545454545455e-06, 'epoch': 3.73}                                          
{'loss': 0.0874, 'grad_norm': 1.0332229137420654, 'learning_rate': 4.734545454545455e-06, 'epoch': 3.82}                                          
{'loss': 0.0877, 'grad_norm': 1.1037228107452393, 'learning_rate': 4.370909090909091e-06, 'epoch': 3.91}                                          
{'loss': 0.0848, 'grad_norm': 0.7284991145133972, 'learning_rate': 4.007272727272727e-06, 'epoch': 4.0}                                           
 80%|██████████████████████████████████████████████████████████████████████████████▍                   | 22004/27500 [6:36:41<1:23:29,  1.10it/s]Trainer is attempting to log a value of "{'asm_Beng': {'precision': 0.9910358565737052, 'recall': 0.995, 'f1-score': 0.9930139720558883, 'support': 1000.0}, 'ben_Beng': {'precision': 1.0, 'recall': 0.999, 'f1-score': 0.9994997498749375, 'support': 1000.0}, 'brx_deva': {'precision': 0.9617706237424547, 'recall': 0.956, 'f1-score': 0.958876629889669, 'support': 1000.0}, 'doi_Deva': {'precision': 0.9783549783549783, 'recall': 0.904, 'f1-score': 0.9397089397089398, 'support': 1000.0}, 'eng_Latn': {'precision': 0.999000999000999, 'recall': 1.0, 'f1-score': 0.9995002498750625, 'support': 1000.0}, 'gom_deva': {'precision': 0.9664694280078896, 'recall': 0.98, 'f1-score': 0.9731876861966237, 'support': 1000.0}, 'guj_Gujr': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'hin_Deva': {'precision': 0.994, 'recall': 0.994, 'f1-score': 0.994, 'support': 1000.0}, 'kan_Knda': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'kas_Arab': {'precision': 0.9969849246231156, 'recall': 0.992, 'f1-score': 0.9944862155388471, 'support': 1000.0}, 'mai_Deva': {'precision': 0.7981803143093466, 'recall': 0.965, 'f1-score': 0.8736985061113626, 'support': 1000.0}, 'mal_Mlym': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'mar_Deva': {'precision': 0.9918946301925026, 'recall': 0.979, 'f1-score': 0.9854051333668847, 'support': 1000.0}, 'mni_Mtei': {'precision': 0.667479674796748, 'recall': 0.821, 'f1-score': 0.736322869955157, 'support': 1000.0}, 'npi_Deva': {'precision': 0.972457627118644, 'recall': 0.918, 'f1-score': 0.9444444444444444, 'support': 1000.0}, 'ory_Orya': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'pan_Guru': {'precision': 1.0, 'recall': 0.999, 'f1-score': 0.9994997498749375, 'support': 1000.0}, 'sat_olck': {'precision': 0.7682291666666666, 'recall': 0.59, 'f1-score': 0.667420814479638, 'support': 1000.0}, 'snd_Deva': {'precision': 0.9881720430107527, 'recall': 0.919, 'f1-score': 0.9523316062176166, 'support': 1000.0}, 'tam_Taml': {'precision': 0.999, 'recall': 0.999, 'f1-score': 0.999, 'support': 1000.0}, 'tel_Telu': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'urd_Arab': {'precision': 0.9930139720558883, 'recall': 0.995, 'f1-score': 0.994005994005994, 'support': 1000.0}, 'accuracy': 0.9547727272727272, 'macro avg': {'precision': 0.9575474653842587, 'recall': 0.9547727272727272, 'f1-score': 0.9547455709816365, 'support': 22000.0}, 'weighted avg': {'precision': 0.9575474653842587, 'recall': 0.9547727272727272, 'f1-score': 0.9547455709816365, 'support': 22000.0}}" of type <class 'dict'> for key "eval/classification_report" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.
{'eval_loss': 0.10861385613679886, 'eval_accuracy': 0.9547727272727272, 'eval_classification_report': {'asm_Beng': {'precision': 0.9910358565737052, 'recall': 0.995, 'f1-score': 0.9930139720558883, 'support': 1000.0}, 'ben_Beng': {'precision': 1.0, 'recall': 0.999, 'f1-score': 0.9994997498749375, 'support': 1000.0}, 'brx_deva': {'precision': 0.9617706237424547, 'recall': 0.956, 'f1-score': 0.958876629889669, 'support': 1000.0}, 'doi_Deva': {'precision': 0.9783549783549783, 'recall': 0.904, 'f1-score': 0.9397089397089398, 'support': 1000.0}, 'eng_Latn': {'precision': 0.999000999000999, 'recall': 1.0, 'f1-score': 0.9995002498750625, 'support': 1000.0}, 'gom_deva': {'precision': 0.9664694280078896, 'recall': 0.98, 'f1-score': 0.9731876861966237, 'support': 1000.0}, 'guj_Gujr': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'hin_Deva': {'precision': 0.994, 'recall': 0.994, 'f1-score': 0.994, 'support': 1000.0}, 'kan_Knda': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'kas_Arab': {'precision': 0.9969849246231156, 'recall': 0.992, 'f1-score': 0.9944862155388471, 'support': 1000.0}, 'mai_Deva': {'precision': 0.7981803143093466, 'recall': 0.965, 'f1-score': 0.8736985061113626, 'support': 1000.0}, 'mal_Mlym': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'mar_Deva': {'precision': 0.9918946301925026, 'recall': 0.979, 'f1-score': 0.9854051333668847, 'support': 1000.0}, 'mni_Mtei': {'precision': 0.667479674796748, 'recall': 0.821, 'f1-score': 0.736322869955157, 'support': 1000.0}, 'npi_Deva': {'precision': 0.972457627118644, 'recall': 0.918, 'f1-score': 0.9444444444444444, 'support': 1000.0}, 'ory_Orya': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'pan_Guru': {'precision': 1.0, 'recall': 0.999, 'f1-score': 0.9994997498749375, 'support': 1000.0}, 'sat_olck': {'precision': 0.7682291666666666, 'recall': 0.59, 'f1-score': 0.667420814479638, 'support': 1000.0}, 'snd_Deva': {'precision': 0.9881720430107527, 'recall': 0.919, 'f1-score': 0.9523316062176166, 'support': 1000.0}, 'tam_Taml': {'precision': 0.999, 'recall': 0.999, 'f1-score': 0.999, 'support': 1000.0}, 'tel_Telu': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1000.0}, 'urd_Arab': {'precision': 0.9930139720558883, 'recall': 0.995, 'f1-score': 0.994005994005994, 'support': 1000.0}, 'accuracy': 0.9547727272727272, 'macro avg': {'precision': 0.9575474653842587, 'recall': 0.9547727272727272, 'f1-score': 0.9547455709816365, 'support': 22000.0}, 'weighted avg': {'precision': 0.9575474653842587, 'recall': 0.9547727272727272, 'f1-score': 0.9547455709816365, 'support': 22000.0}}, 'eval_runtime': 104.7123, 'eval_samples_per_second': 210.099, 'eval_steps_per_second': 13.131, 'epoch': 4.0}
{'loss': 0.0809, 'grad_norm': 0.8425612449645996, 'learning_rate': 3.643636363636364e-06, 'epoch': 4.09}                                          
{'loss': 0.0782, 'grad_norm': 0.7532763481140137, 'learning_rate': 3.280727272727273e-06, 'epoch': 4.18}
{'loss': 0.0769, 'grad_norm': 0.17686280608177185, 'learning_rate': 2.9170909090909094e-06, 'epoch': 4.27}                                        
{'loss': 0.0866, 'grad_norm': 13.3302640914917, 'learning_rate': 2.5534545454545458e-06, 'epoch': 4.36}                                           
{'loss': 0.0801, 'grad_norm': 0.45403754711151123, 'learning_rate': 2.189818181818182e-06, 'epoch': 4.45}                                         
{'loss': 0.0773, 'grad_norm': 0.5394322872161865, 'learning_rate': 1.8261818181818183e-06, 'epoch': 4.54}                                         
{'loss': 0.0802, 'grad_norm': 1.4982187747955322, 'learning_rate': 1.4625454545454546e-06, 'epoch': 4.64}                                         
 93%|████████████████████████████████████████████████████████████████████████████████████████████▉       | 25546/27500 [7:40:18<33:25,  1.03s/it
